{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once deleted, variables cannot be recovered. Proceed (y/[n])? y\n"
     ]
    }
   ],
   "source": [
    "%reset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "_uuid": "65325a440b9f673114f02d524169da977e6d2c0e"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import time\n",
    "import re\n",
    "sns.set()\n",
    "%matplotlib notebook\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.options.display.max_columns = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "_uuid": "2b1b986643ed3c4f410e0671b36ec5ec17700c18"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['test_images', 'breed_labels.csv', '.DS_Store', 'test', 'train_metadata', 'color_labels.csv', 'test_sentiment', 'test_metadata', 'train_sentiment', 'train', 'train_images', 'state_labels.csv']\n"
     ]
    }
   ],
   "source": [
    "KAGGLE_DIR = 'data/'\n",
    "#KAGGLE_DIR = '../input/'\n",
    "\n",
    "import os\n",
    "print(os.listdir(KAGGLE_DIR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "_uuid": "110c2b93262c7bbe1843bac375f53e69fa1b9b9c"
   },
   "outputs": [],
   "source": [
    "\n",
    "train=pd.read_csv(KAGGLE_DIR+'train/train.csv')\n",
    "test=pd.read_csv(KAGGLE_DIR+'test/test.csv')\n",
    "breed_labels=pd.read_csv(KAGGLE_DIR+'breed_labels.csv')\n",
    "breed_labels['tipo_animal']= np.where(breed_labels['Type']==1,'Dog','Cat')  #Difference between animals\n",
    "color_labels=pd.read_csv(KAGGLE_DIR+'color_labels.csv')\n",
    "color_labels.set_index('ColorID',inplace=True)\n",
    "state_labels=pd.read_csv(KAGGLE_DIR+'state_labels.csv')\n",
    "full=train.append(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "_uuid": "7b8a2f1b3e85b6c8560b3bf75a67e2a34286ee43"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14993, 24)\n",
      "(3948, 23)\n",
      "(18941, 24)\n"
     ]
    }
   ],
   "source": [
    "print(train.shape)\n",
    "print(test.shape)\n",
    "print(full.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "full['SecondaryColors']=full['Color2']+full['Color3']\n",
    "full['MonoColor']=np.where(full['SecondaryColors'],1,0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "full['State_3']=full.State.map(lambda x: \"{:05}\".format(x)[:3])\n",
    "full['State_4']=full.State.map(lambda x: \"{:05}\".format(x)[:4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "full['LessThanAYear']=np.where(full['Age']<12,1,0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comentario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "full['Description_Count'] = full['Description'].str.len()\n",
    "full['hasName'] = (full.Name.isna()).astype(int)\n",
    "\n",
    "\n",
    "full['Name_Len']=full['Name'].str.len()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pet size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "full['BigSizePet']= np.where(full['MaturitySize']>2,1,0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Health"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "full['isHealthy']= np.where(full['Health']>1,1,0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dewormed & Vaccinated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "full['isDewormed']= np.where(full['Dewormed']>1,1,0)\n",
    "full['isVaccinated']= np.where(full['Vaccinated']>1,1,0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unico o camada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "full['isLonely']=np.where(full['Quantity']>1,1,0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Free"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "full['isFree']=np.where(full['Fee']>0,1,0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mean Encodings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Mean Encoding Function\n",
    "def Target_encoding(df,element,target):\n",
    "    #create aux    \n",
    "    aux_df = pd.DataFrame(df.groupby(element)[target].mean())\n",
    "\n",
    "    #change name\n",
    "    aux_df[element+'_ENCODED'] = aux_df[target]\n",
    "    aux_df= aux_df.drop(target, axis=1)\n",
    "\n",
    "    #join\n",
    "    df = df.join(aux_df, how = 'left', on = element) \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "def splited_target_encoding(df,query_train,query_test,element,target):\n",
    "    entrenamiento=df.query(query_train)\n",
    "    testeo=df.query(query_test)\n",
    "    \n",
    "    entrenamiento=Target_encoding(entrenamiento,element,target)\n",
    "    \n",
    "    inputZIP1=element\n",
    "    inputZIP2=element+'_ENCODED'\n",
    "    \n",
    "    mydict=dict(zip(entrenamiento[inputZIP1],entrenamiento[inputZIP2]))\n",
    "    testeo[element+'_ENCODED']=testeo[element].map(mydict)\n",
    "    return entrenamiento.append(testeo)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Zip Encodings\n",
    "full=splited_target_encoding(full,'AdoptionSpeed!=\"NaN\"','AdoptionSpeed==\"NaN\"','State_4','AdoptionSpeed')\n",
    "full=splited_target_encoding(full,'AdoptionSpeed!=\"NaN\"','AdoptionSpeed==\"NaN\"','State_3','AdoptionSpeed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [1,2,3,4,5]\n",
    "full['AgeBins'] = pd.cut(full['Age'],5,labels=labels)\n",
    "full=splited_target_encoding(full,'AdoptionSpeed!=\"NaN\"','AdoptionSpeed==\"NaN\"','AgeBins','AdoptionSpeed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "full=splited_target_encoding(full,'AdoptionSpeed!=\"NaN\"','AdoptionSpeed==\"NaN\"','Breed1','AdoptionSpeed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "full['FullBlack']=np.where((full['Color1']==1) & (full['MonoColor']==0),1,0)\n",
    "full['FullWhite']=np.where((full['Color1']==7) & (full['MonoColor']==0),1,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "full=splited_target_encoding(full,'AdoptionSpeed!=\"NaN\"','AdoptionSpeed==\"NaN\"','RescuerID','AdoptionSpeed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [1,2,3,4,5]\n",
    "full['FeeBins'] = pd.cut(full['Fee'],5,labels=labels)\n",
    "full=splited_target_encoding(full,'AdoptionSpeed!=\"NaN\"','AdoptionSpeed==\"NaN\"','FeeBins','AdoptionSpeed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18941, 48)"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       2.000000\n",
       "1       0.000000\n",
       "2       2.368192\n",
       "3       2.640000\n",
       "4       1.970149\n",
       "5       2.000000\n",
       "6       1.800000\n",
       "7       2.333333\n",
       "8       2.714286\n",
       "9       4.000000\n",
       "10      2.640000\n",
       "11      2.333333\n",
       "12      2.019231\n",
       "13      1.000000\n",
       "14      2.000000\n",
       "15      4.000000\n",
       "16      2.000000\n",
       "17      4.000000\n",
       "18      2.640000\n",
       "19      3.000000\n",
       "20      2.800000\n",
       "21      4.000000\n",
       "22      4.000000\n",
       "23      2.603175\n",
       "24      1.363636\n",
       "25      2.639344\n",
       "26      1.000000\n",
       "27      2.333333\n",
       "28      3.000000\n",
       "29      2.181818\n",
       "          ...   \n",
       "3918         NaN\n",
       "3919         NaN\n",
       "3920         NaN\n",
       "3921         NaN\n",
       "3922         NaN\n",
       "3923         NaN\n",
       "3924         NaN\n",
       "3925         NaN\n",
       "3926         NaN\n",
       "3927         NaN\n",
       "3928         NaN\n",
       "3929         NaN\n",
       "3930         NaN\n",
       "3931         NaN\n",
       "3932         NaN\n",
       "3933         NaN\n",
       "3934         NaN\n",
       "3935         NaN\n",
       "3936         NaN\n",
       "3937         NaN\n",
       "3938         NaN\n",
       "3939         NaN\n",
       "3940         NaN\n",
       "3941         NaN\n",
       "3942         NaN\n",
       "3943         NaN\n",
       "3944         NaN\n",
       "3945         NaN\n",
       "3946         NaN\n",
       "3947         NaN\n",
       "Name: RescuerID_ENCODED, Length: 18941, dtype: float64"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full.RescuerID_ENCODED"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets fill de na\n",
    "full.Description_Count.fillna(0,inplace=True)\n",
    "full.Name_Len.fillna(0,inplace=True)\n",
    "# Spliting the data\n",
    "test=full.query('AdoptionSpeed ==\"NaN\"')\n",
    "train=full.query('AdoptionSpeed !=\"NaN\"')\n",
    "target=train['AdoptionSpeed']\n",
    "train.drop(columns=['AdoptionSpeed','Description','Name','PetID','RescuerID','RescuerID_ENCODED'],inplace=True)\n",
    "test.drop(columns=['AdoptionSpeed','Name', 'RescuerID', 'Description', 'PetID','RescuerID_ENCODED'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, AdaBoostClassifier\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "# Seed for reproducability\n",
    "seed = 12345\n",
    "np.random.seed(seed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metric used for this competition (Quadratic Weigthed Kappa aka Cohen Kappa Score)\n",
    "def metric(y1,y2):\n",
    "    return cohen_kappa_score(y1,y2, weights='quadratic')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "3f0b23822d66983472c8d623728ad350102633da"
   },
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "_uuid": "7f39b25e8bcb87d359aba84698a3db021ffec518"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': [200, 650, 1100, 1550, 2000], 'max_features': ['auto', 'sqrt'], 'max_depth': [10, 35, 60, 85, 110, None], 'min_samples_split': [2, 5, 10], 'min_samples_leaf': [1, 2, 4], 'bootstrap': [True]}\n",
      "The time elapsed is 0.0s\n"
     ]
    }
   ],
   "source": [
    "tic=time.time()\n",
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 5)]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 5)]\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True]\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}\n",
    "print(random_grid)\n",
    "toc=time.time()\n",
    "print('The time elapsed is {}s'.format(np.round(np.abs(tic-toc))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Has nans?\n",
    "train.isna().sum().sum()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "_uuid": "d44daa4352a699319e0d5093bed73a3bf409c857",
    "scrolled": false
   },
   "source": [
    "# Use the random grid to search for best hyperparameters\n",
    "# First create the base model to tune\n",
    "rf = RandomForestClassifier()\n",
    "# Random search of parameters, using 3 fold cross validation, \n",
    "# search across 100 different combinations, and use all available cores\n",
    "rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 100, cv = 3, verbose=2, random_state=42, n_jobs = -1)\n",
    "# Fit the random search model\n",
    "rf_random.fit(train, target)\n",
    "rf_random.best_params_"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "_uuid": "05624d4dbc01752370ec5e16b578471a51153a75"
   },
   "source": [
    "{'n_estimators': 1100,\n",
    " 'min_samples_split': 2,\n",
    " 'min_samples_leaf': 1,\n",
    " 'max_features': 'auto',\n",
    " 'max_depth': 110,\n",
    " 'bootstrap': True}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=60, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=1100, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf=RandomForestClassifier(n_estimators=1100,min_samples_split=2,min_samples_leaf=1,max_features='auto',max_depth=60,bootstrap=True)\n",
    "rf.fit(train,target)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9989653186984565"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Measure of performance \n",
    "# Useful for checking overfitting, performance, etc.\n",
    "metric(rf.predict(train), target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extratrees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "extra_trees = ExtraTreesClassifier(bootstrap=False, class_weight=None, criterion='entropy',\n",
    "           max_depth=83, max_features='auto', max_leaf_nodes=None,\n",
    "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "           min_samples_leaf=5, min_samples_split=10,\n",
    "           min_weight_fraction_leaf=0.0, n_estimators=225, n_jobs=1,\n",
    "           oob_score=False, random_state=None, verbose=0, warm_start=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "## Searched the space once to see the best parameters\n",
    "clf2 = ExtraTreesClassifier()\n",
    "extra_trees_grid = {\n",
    "    'bootstrap' : [False, True], \n",
    "    'criterion' : ['gini', 'entropy'], \n",
    "    'max_depth' : [77, 80, 83, 85], \n",
    "    'max_features': ['auto'], \n",
    "    'min_samples_leaf': [5, 10], \n",
    "    'min_samples_split': [5, 10],\n",
    "    'n_estimators': [175, 200, 225]\n",
    "}\n",
    "extra_trees_gridsearch = GridSearchCV(estimator = clf2, \n",
    "                           param_grid = extra_trees_grid, \n",
    "                           cv = 3, \n",
    "                           n_jobs = -1, \n",
    "                           verbose = 1)\n",
    "extra_trees_gridsearch.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ExtraTreesClassifier(bootstrap=False, class_weight=None, criterion='entropy',\n",
       "           max_depth=83, max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "           min_samples_leaf=5, min_samples_split=10,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators=225, n_jobs=1,\n",
       "           oob_score=False, random_state=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extra_trees.fit(train,target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6411256394135593"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric(extra_trees.predict(train), target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CatBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from catboost import CatBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: -1.4193188\ttotal: 235ms\tremaining: 235ms\n",
      "1:\tlearn: -1.3749724\ttotal: 405ms\tremaining: 0us\n"
     ]
    }
   ],
   "source": [
    "cb = CatBoostClassifier(iterations=2, learning_rate=1, depth=8, loss_function='MultiClass')\n",
    "cb.fit(train,target);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2939917054500589"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric(cb.predict(train), target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adaboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "adab=AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,\n",
    "          learning_rate=0.3, n_estimators=200, random_state=None)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "adab=AdaBoostClassifier()\n",
    "adaboost_grid = {\n",
    "    'n_estimators' : [200, 225, 250],\n",
    "    'learning_rate' : [.1, .2 , .3, .4, .5],\n",
    "    'algorithm' : ['SAMME.R']\n",
    "}\n",
    "adaboost_gridsearch = GridSearchCV(estimator = adab, \n",
    "                           param_grid = adaboost_grid, \n",
    "                           cv = 3, \n",
    "                           n_jobs = -1, \n",
    "                           verbose = 1)\n",
    "adaboost_gridsearch.fit(train, target)\n",
    "adaboost_gridsearch.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,\n",
       "          learning_rate=0.3, n_estimators=200, random_state=None)"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adab.fit(train,target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.36027630702137936"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Measure of performance \n",
    "# Useful for checking overfitting, performance, etc.\n",
    "metric(adab.predict(train), target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2414062624902521"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "gauss=GaussianNB()\n",
    "gauss.fit(train,target)\n",
    "metric(gauss.predict(train), target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance of the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest score:  0.9989653186984565\n",
      "Extra Trees score:    0.6411256394135593\n",
      "Adaboost score:       0.36027630702137936\n",
      "Catboos score:        0.2939917054500589\n",
      "GaussianNB score:     0.2414062624902521\n"
     ]
    }
   ],
   "source": [
    "print('Random Forest score: ', metric(rf.predict(train), \n",
    "                                target))\n",
    "print('Extra Trees score:   ', metric(extra_trees.predict(train), \n",
    "                                target))\n",
    "print('Adaboost score:      ', metric(adab.predict(train), \n",
    "                                target))\n",
    "print('Catboos score:       ', metric(cb.predict(train), \n",
    "                                target))\n",
    "print('GaussianNB score:    ', metric(gauss.predict(train), \n",
    "                                target))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensambling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.Breed1_ENCODED.fillna(0,inplace=True)\n",
    "test.isna().sum().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get predictions\n",
    "predictions1 = rf.predict(test)\n",
    "predictions2 = extra_trees.predict(test)\n",
    "predictions3 = adab.predict(test)\n",
    "predictions4 = gauss.predict(test)\n",
    "predictions5 = cb.predict_proba(test)[:, 1]\n",
    "\n",
    "# Combine predictions\n",
    "final_predictions = []\n",
    "# Get average of predictions\n",
    "for pred in zip(predictions1, predictions2, predictions3, predictions4,predictions5):\n",
    "    final_predictions.append(int(round((sum(pred)) / 5, 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Random Forest</th>\n",
       "      <th>Extra Trees</th>\n",
       "      <th>Adaboost</th>\n",
       "      <th>GaussianNB</th>\n",
       "      <th>Catboost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.211127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.093984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.045199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.126196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.054236</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Random Forest  Extra Trees  Adaboost  GaussianNB  Catboost\n",
       "0            2.0          2.0       2.0         2.0  0.211127\n",
       "1            4.0          4.0       4.0         4.0  0.093984\n",
       "2            4.0          4.0       4.0         1.0  0.045199\n",
       "3            4.0          4.0       4.0         2.0  0.126196\n",
       "4            4.0          4.0       4.0         2.0  0.054236"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compare predictions\n",
    "prediction_df = pd.DataFrame({'Random Forest' : predictions1,\n",
    "                              'Extra Trees'   : predictions2,\n",
    "                              'Adaboost'      : predictions3,\n",
    "                              'GaussianNB'    : predictions4,\n",
    "                              'Catboost'      : predictions5,\n",
    "})\n",
    "\n",
    "prediction_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "e77c152ef96eabc2beb2b56ccee113e726003bb1"
   },
   "source": [
    "### Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "_uuid": "ec2caf21ed2249fc6c56cdc6e40236ba1265d6b7"
   },
   "outputs": [],
   "source": [
    "# Get and store predictions\n",
    "\n",
    "test=pd.read_csv(KAGGLE_DIR+'test/test.csv')\n",
    "submission_df = pd.DataFrame(data={\"PetID\" : test[\"PetID\"], \n",
    "                                   \"AdoptionSpeed\" : final_predictions})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "_uuid": "0eb1082bcc973fe54b276d2047186f5e8ffec849"
   },
   "outputs": [],
   "source": [
    "submission_df['AdoptionSpeed']=submission_df['AdoptionSpeed'].astype('int32');\n",
    "submission_df.to_csv(\"sample_submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "_uuid": "49b82b2f528694bf0a3b03629ddc90f553a60431",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PetID</th>\n",
       "      <th>AdoptionSpeed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>378fcc4fc</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>73c10e136</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>72000c4c5</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>e147a4b9f</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>43fbba852</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       PetID  AdoptionSpeed\n",
       "0  378fcc4fc              2\n",
       "1  73c10e136              3\n",
       "2  72000c4c5              3\n",
       "3  e147a4b9f              3\n",
       "4  43fbba852              3"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission_df.head()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "To try to do text mining\n",
    "# Get the tfidf vectors #\n",
    "tfidf_vec = TfidfVectorizer(stop_words='english',ngram_range=(1,3),encoding='utf-8')\n",
    "tfidf_vec.fit_transform(train_df['Description'].values.astype(\"U\").tolist() + test_df['Description'].values.astype(\"U\").tolist())\n",
    "train_tfidf = tfidf_vec.transform(train_df['Description'].astype(\"U\").values.tolist())\n",
    "test_tfidf = tfidf_vec.transform(test_df['Description'].astype(\"U\").values.tolist())\n",
    "Baseline Model\n",
    "\n",
    "train_y = train_df[\"AdoptionSpeed\"].values\n",
    "model = RandomForestClassifier(n_estimators=100, max_depth=2,random_state=2019)\n",
    "model.fit(train_tfidf, train_y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
